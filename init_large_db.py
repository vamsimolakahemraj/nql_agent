#!/usr/bin/env python3
"""
Initialize large-scale database for NQL Agent demonstration
This script will generate 400k+ records across multiple tables
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.database import DatabaseManager

def main():
    print("ğŸš€ Initializing Large-Scale NQL Agent Database")
    print("=" * 60)
    print("This will generate:")
    print("  â€¢ 50,000 users")
    print("  â€¢ 10,000 products") 
    print("  â€¢ 100,000 orders")
    print("  â€¢ 200,000 order items")
    print("  â€¢ 50,000 reviews")
    print("  â€¢ 10 categories")
    print("=" * 60)
    
    response = input("This may take 10-15 minutes. Continue? (y/N): ")
    if response.lower() != 'y':
        print("Cancelled.")
        return
    
    try:
        db_manager = DatabaseManager()
        print("\nğŸ—„ï¸  Initializing database...")
        db_manager.initialize_sample_data()
        
        print("\nâœ… Large-scale database initialization completed!")
        print("\nğŸ“Š Database Statistics:")
        schema = db_manager.get_schema()
        for table_name, table_info in schema.items():
            print(f"  â€¢ {table_name}: {table_info['row_count']:,} rows")
        
        total_records = sum(table_info['row_count'] for table_info in schema.values())
        print(f"\nğŸ¯ Total Records: {total_records:,}")
        print("\nğŸŒ Your NQL Agent is ready with enterprise-scale data!")
        
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()

